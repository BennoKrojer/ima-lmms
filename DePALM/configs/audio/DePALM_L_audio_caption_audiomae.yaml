image_res: 224
batch_size_train: 2




optimizer: {opt: adamW, lr: 2e-4, weight_decay: 0.02, prompt_lr: 1e-3}
schedular: {sched: cosine, scheduler_groups: 0 , lr: 2e-4, epochs: 20, min_lr: 1e-5, decay_rate: 1, warmup_lr: 1e-4, warmup_epochs: 4, cooldown_epochs: 0}

use_vis_prefix: True
# start_layer_idx: 19
# end_layer_idx: 31
start_layer_idx: 0
end_layer_idx: 1



injected_hidden_states: 1
shared_connector: True

lm_loss_weight: 0.1

unfreeze_text_layer_norm: False
unfreeze_vision_layer_norm: False


num_workers: 4



replace_added_tokens: True


use_cache: False

shift_labels: False

append_eos_token: True

num_beams: 3
do_sample: False



# Prompt tuning
# prompt_tuning: True
prompt_len: 10
prompt_lr: 1e-3
mlp: False

batch_size_test: 8


interaction_type: cat


target: prompt
residual: True
use_attention_film: True
interaction_config: {'frozen': False} # qsformer


# connector_type: cnn
connector_type: trans
multihead_connector: True

## token pruning
vis_tokens: all



connector_config: {'hidden_dim': 256, 'num_heads': 8, 'num_layers': 5, 'output_length': 10, 'activation': 'relu', 'qs_former': True} # qsformer


inject_outside: True



dataset_name: 'audiocaps'

train_split: 'audiocaps_caption_train'
val_split: 'audiocaps_caption_val'
test_split: 'audiocaps_caption_test'


melbins: 128
target_length: 1024
num_tries: 4

skip_norm: False
norm_mean: -4.2677393
norm_std: 4.5689974
noise: False

freqm_p: 24
timem_p: 96
