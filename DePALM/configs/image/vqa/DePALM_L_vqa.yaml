image_res: 224
batch_size_train: 8



warm_up: True



optimizer: {opt: adamW, lr: 2e-4, weight_decay: 0.02, prompt_lr: 1e-3}
schedular: {sched: cosine, scheduler_groups: 0 , lr: 2e-4, epochs: 20, min_lr: 1e-5, decay_rate: 1, warmup_lr: 1e-4, warmup_epochs: 4, cooldown_epochs: 0}

use_vis_prefix: True
# start_layer_idx: 19
# end_layer_idx: 31
start_layer_idx: 0
end_layer_idx: 1
# start_layer_idx: 1
# end_layer_idx: 31
# interaction_step: 4
# start_layer_idx: 0
# end_layer_idx: 31
# select_higher_step: True
# interaction_step: 4


injected_hidden_states: 1
shared_connector: True

lm_loss_weight: 0.1

unfreeze_text_layer_norm: False
unfreeze_vision_layer_norm: False


num_workers: 4



replace_added_tokens: True


use_cache: False

shift_labels: False

append_eos_token: True

num_beams: 3
do_sample: False



# Prompt tuning
# prompt_tuning: True
prompt_len: 10
prompt_lr: 1e-3
mlp: False

batch_size_test: 8

## save hidden states
# valid_topk: 40
# batch_size_test: 1
# save_hidden_states: True
# num_beams: 1

interaction_type: cat
# interaction_type: qsformer

# interaction_type: ['cat', 'ca']
# target: ['prompt', 'all']

target: prompt
residual: True
use_attention_film: True
interaction_config: {'frozen': False} # qsformer


# connector_type: cnn
connector_type: trans
multihead_connector: True

## token pruning
vis_tokens: all
# extraction_config: {'extraction': 'pool', 'num_layers': 3, 'token_pruning_config': {'pruning_method': 'keepbestclusters', 'steps': 1, 'rate': 3}}
# extraction_config: {'extraction': 'avg', 'num_layers': 3,} # ePALM_L_vqa_l0_1_qsformerl10catwithtext_3lavg_clipl
# extraction_config: {'extraction': 'avg', 'num_layers': 6,} # ePALM_L_vqa_l0_1_qsformerl10catwithtext_6lavg_clipl, ePALM_L_vqa_l0_1_qsformerl10cawithtextl1_6lavg_clipl




# connector_config: {'hidden_dim': 256, 'num_heads': 8, 'num_layers': 5, 'output_length': 10, 'activation': 'relu', 'qs_former': True} # qsformer
# connector_config: {'hidden_dim': 256, 'num_heads': 8, 'num_layers': 5, 'output_length': 10, 'activation': 'relu', 'qs_former': True, 'qs_former_with_text': True, 'interleaved_qs_former': True, 'cat_with_text': True, 'text_feat_num_layers': 0} # qsformer
# connector_config: {'hidden_dim': 256, 'num_heads': 8, 'num_layers': 5, 'output_length': 10, 'activation': 'relu', 'qs_former': True, 'qs_former_with_text': True, 'interleaved_qs_former': True, 'cat_with_text': False, 'text_feat_num_layers': 0} # qsformer
# connector_config: {'hidden_dim': 256, 'num_heads': 8, 'num_layers': 5, 'output_length': 10, 'activation': 'relu', 'qs_former': True, 'qs_former_with_text': True, 'interleaved_qs_former': True, 'cat_with_text': True, 'text_feat_num_layers': 1} # qsformer
# connector_config: {'hidden_dim': 256, 'num_heads': 8, 'num_layers': 5, 'output_length': 10, 'activation': 'relu', 'qs_former': True, 'qs_former_with_text': True, 'interleaved_qs_former': True, 'cat_with_text': False, 'text_feat_num_layers': 0, 'qs_former_with_film': True, 'interleaved_with_text': False} # qsformer
# connector_config: {'hidden_dim': 256, 'num_heads': 8, 'num_layers': 5, 'output_length': 10, 'activation': 'relu', 'qs_former': True, 'qs_former_with_text': True, 'interleaved_qs_former': True, 'cat_with_text': False, 'text_feat_num_layers': 0, 'qs_former_with_film': False, 'interleaved_with_text': True, 'ca_with_text': True} # ePALM_L_vqa_l0_1_qsformerl10cawithtext_clipl
# connector_config: {'hidden_dim': 256, 'num_heads': 8, 'num_layers': 5, 'output_length': 10, 'activation': 'relu', 'qs_former': True, 'qs_former_with_text': True, 'interleaved_qs_former': True, 'cat_with_text': True, 'text_feat_num_layers': 0, 'token_pruning_config': {'pruning_method': 'keepbestclusters', 'steps': 1, 'rate': 2}} # qsformer
# connector_config: {'hidden_dim': 256, 'num_heads': 8, 'num_layers': 5, 'output_length': 10, 'activation': 'relu', 'qs_former': True, 'qs_former_with_text': True, 'interleaved_qs_former': True, 'cat_with_text': True, 'text_feat_num_layers': 0,} # qsformer # ePALM_L_vqa_l0_1_qsformerl10catwithtext_6lavg_clipl
# connector_config: {'hidden_dim': 256, 'num_heads': 8, 'num_layers': 5, 'output_length': 20, 'activation': 'relu', 'qs_former': True, 'qs_former_with_text': True, 'interleaved_qs_former': True, 'cat_with_text': True, 'text_feat_num_layers': 0, 'token_pruning_config': {'pruning_method': 'tome', 'steps': 2, 'rate': 0.25, 'with_cls_token': False, 'token_prune_target': 'query'}} # qsformer ePALM_L_vqa_l0_1_qsformerl20catwithtext_qpooltomer05_clipl
# connector_config: {'hidden_dim': 256, 'num_heads': 8, 'num_layers': 5, 'output_length': 10, 'activation': 'relu', 'qs_former': True, 'qs_former_with_text': True, 'interleaved_qs_former': True, 'cat_with_text': True, 'text_feat_num_layers': 0, 'qs_former_with_film': False, 'interleaved_with_text': False, 'ca_with_text': True} # ePALM_L_vqa_l0_1_qsformerl10cawithtextcatwithtext_clipl
# connector_config: {'hidden_dim': 256, 'num_heads': 8, 'num_layers': 5, 'output_length': 10, 'activation': 'relu', 'qs_former': True, 'qs_former_with_text': True, 'interleaved_qs_former': True, 'cat_with_text': True, 'text_feat_num_layers': 0, 'img_with_text': True} # ePALM_L_vqa_l0_1_qsformerl10catwithtextimgwithtext_clipl
# connector_config: {'hidden_dim': 256, 'num_heads': 8, 'num_layers': 5, 'output_length': 10, 'activation': 'relu', 'qs_former': True, 'qs_former_with_text': True, 'interleaved_qs_former': True, 'cat_with_text': False, 'text_feat_num_layers': 1, 'interleaved_with_text': True, 'ca_with_text': True,} # qsformer # ePALM_L_vqa_l0_1_qsformerl10cawithtextl1_6lavg_clipl
connector_config: {'hidden_dim': 256, 'num_heads': 8, 'num_layers': 5, 'output_length': 10, 'activation': 'relu', 'qs_former': True, 'qs_former_with_text': True, 'interleaved_qs_former': True, 'cat_with_text': False, 'text_feat_num_layers': 1, 'interleaved_with_text': True, 'ca_with_text': True, 'img_with_text': True} # qsformer # ePALM_L_vqa_l0_1_qsformerl10cawithtextl1imgwithtext_6lavg_clipl ePALM_L_vqa_l0_1_qsformerl10cawithtextl1imgwithtext_sdm_unetblock2
# connector_config: {'hidden_dim': 512, 'num_heads': 8, 'num_layers': 5, 'output_length': 10, 'activation': 'relu', 'qs_former': True, 'qs_former_with_text': True, 'interleaved_qs_former': True, 'cat_with_text': False, 'text_feat_num_layers': 1, 'interleaved_with_text': True, 'ca_with_text': True, 'img_with_text': True} # qsformer # ePALM_L_vqa_l0_1_qsformerl10cawithtextl1imgwithtextemb512_6lavg_clipl
# connector_config: {'hidden_dim': 512, 'num_heads': 8, 'num_layers': 5, 'output_length': 20, 'activation': 'relu', 'qs_former': True, 'qs_former_with_text': True, 'interleaved_qs_former': True, 'cat_with_text': False, 'text_feat_num_layers': 1, 'interleaved_with_text': True, 'ca_with_text': True, 'img_with_text': True} # qsformer # ePALM_L_vqa_l0_1_qsformerl20cawithtextl1imgwithtextemb512_6lavg_clipl
# connector_config: {'hidden_dim': 256, 'num_heads': 8, 'num_layers': 5, 'output_length': 20, 'activation': 'relu', 'qs_former': True, 'qs_former_with_text': True, 'interleaved_qs_former': True, 'cat_with_text': False, 'text_feat_num_layers': 1, 'interleaved_with_text': True, 'ca_with_text': True, 'img_with_text': True} # qsformer # ePALM_L_vqa_l0_1_qsformerl20cawithtextl1imgwithtext_6lavg_clipl

# connector_config: {'hidden_dim': 256, 'num_heads': 8, 'num_layers': 5, 'output_length': 30, 'activation': 'relu', 'qs_former': True, 'qs_former_with_text': True, 'interleaved_qs_former': True, 'cat_with_text': False, 'text_feat_num_layers': 1, 'interleaved_with_text': True, 'ca_with_text': True, 'img_with_text': True} # qsformer # ePALM_L_vqa_l0_1_qsformerl30samp10cawithtextl1imgwithtex_6lavg_clipl
# num_sampled_tokens: 10 # ePALM_L_vqa_l0_1_qsformerl30samp10cawithtextl1imgwithtex_6lavg_clipl
# keep_cls: False # ePALM_L_vqa_l0_1_qsformerl30samp10cawithtextl1imgwithtex_6lavg_clipl


# connector_config: {'hidden_dim': 256, 'num_heads': 8, 'num_layers': 5, 'output_length': 10, 'activation': 'relu', 'qs_former': True, 'qs_former_with_text': True, 'interleaved_qs_former': True, 'cat_with_text': False, 'text_feat_num_layers': 1, 'interleaved_with_text': True, 'ca_with_text': True, 'img_with_text': True, 'num_sampled_img_tokens': 0.5, 'num_sampled_text_tokens': 0.8} # qsformer # ePALM_L_vqa_l0_1_qsformerl10cawithtextl1imgwithtext_sampleimg0_5text0_80_6lavg_clipl
# connector_config: {'hidden_dim': 256, 'num_heads': 8, 'num_layers': 5, 'output_length': 10, 'activation': 'relu', 'qs_former': True, 'qs_former_with_text': True, 'interleaved_qs_former': True, 'cat_with_text': False, 'text_feat_num_layers': 1, 'interleaved_with_text': True, 'ca_with_text': True, 'img_with_text': True, 'num_sampled_img_tokens': 0.5} # qsformer # ePALM_L_vqa_l0_1_qsformerl10cawithtextl1imgwithtext_sampleimg0_5text0_80_6lavg_clipl
# connector_config: {'hidden_dim': 256, 'num_heads': 8, 'num_layers': 5, 'output_length': 10, 'activation': 'relu', 'qs_former': True, 'qs_former_with_text': True, 'interleaved_qs_former': True, 'cat_with_text': False, 'text_feat_num_layers': 1, 'interleaved_with_text': True, 'ca_with_text': True, 'img_with_text': True, 'num_sampled_img_tokens': [0.6, 1]} # qsformer # ePALM_L_vqa_l0_1_qsformerl10cawithtextl1imgwithtext_sampleimg0_5text0_80_6lavg_clipl




inject_outside: True

test_split: karpathy_test # karpathy_test val
# train_topk: 0.4
max_length: 45

# train_topk: 0.3
# valid_topk: 40
